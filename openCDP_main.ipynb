{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate \n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from skipgram import SkipGram\n",
    "import torch\n",
    "import numpy as np\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.config import Configure\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.util import generate_uuid5\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the file path from the environment variable\n",
    "file_path = os.getenv(\"PATH_TO_ORIGINAL_DATA\")\n",
    "model_path = os.getenv(\"PATH_TO_MODELS\")\n",
    "\n",
    "# define file names and paths\n",
    "dataset_file_name = \"2019-Oct.csv\"\n",
    "pkl_file_name= \"token_map.pkl\"\n",
    "model_file_name = \"finished_OpenCDPEmbedding.pt\"\n",
    "\n",
    "# define the dataset and model file paths\n",
    "dataset = file_path + dataset_file_name\n",
    "vocab_map_file = model_path + pkl_file_name\n",
    "embd_model_file = model_path + model_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns for the dataset\n",
    "columns = [\"event_type\", \"product_id\", \"category_code\"]\n",
    "\n",
    "# Define the data types for each column\n",
    "dtype_mapping = {\n",
    "    \"event_type\": \"category\",\n",
    "    \"product_id\": \"UInt32\",\n",
    "    \"category_code\" : \"category\",\n",
    "}\n",
    "\n",
    "# Define the context size for the SkipGram model\n",
    "context_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source: https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store?select=2019-Oct.csv\n",
    "# Load dataset\n",
    "\n",
    "df = pd.read_csv(dataset, usecols=columns, dtype=dtype_mapping,nrows=3000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['merged'] = df['event_type'].astype(str) + df['product_id'].astype(str)\n",
    "\n",
    "df['merged'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embedding file to estimate the embedding dimension\n",
    "embed_model = torch.load(embd_model_file, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Check embedding dim\n",
    "embedding_weights = embed_model[\"model\"][\"embedding.weight\"]\n",
    "embedding_dim = embedding_weights.shape[1]\n",
    "\n",
    "print(f\"Embedding-Dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary mapping from pickle file\n",
    "with open(vocab_map_file, \"rb\") as f:\n",
    "    vocab_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding\n",
    "embedding = SkipGram.create_from_checkpoint(embd_model_file, vocab_mapping, embedding_dim, context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizes an item using a given model and actions map.\n",
    "def vectorize_item(item_id, model, vocab_map):\n",
    "    if item_id not in vocab_map:\n",
    "        return None  \n",
    "    index = vocab_map[item_id]\n",
    "    index_tensor = torch.tensor([index], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        vector = model.embed(index_tensor).squeeze().numpy()\n",
    "    return vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize all product_ids in the dataframe\n",
    "vectors = []\n",
    "for item_id in df[\"merged\"]:\n",
    "    vector = vectorize_item(item_id, embedding, vocab_mapping)\n",
    "    vectors.append(vector)\n",
    "\n",
    "df[\"vector\"] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['vector'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['category_code'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = df.drop(columns=['event_type', 'merged'])\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = df_product.dropna()\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"RecommenderDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema with the properties and no vectorizer (as we already have the vectors)\n",
    "recommendations = client.collections.create(\n",
    "    name=\"RecommenderDB\",\n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n",
    "    properties=[\n",
    "        wvc.config.Property(name=\"product_id\", data_type=wvc.config.DataType.INT),\n",
    "        wvc.config.Property(name=\"category_code\", data_type=wvc.config.DataType.TEXT),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommencations = client.collections.get(\"RecommenderDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter context manager\n",
    "with recommencations.batch.dynamic() as batch:\n",
    "    # Loop through the data\n",
    "    for i, row in enumerate(df_product.itertuples(index=False)):\n",
    "        recommendation_objs = {\n",
    "            \"product_id\": row.product_id,\n",
    "            \"category_code\": row.category_code,\n",
    "        }\n",
    "        # Get the vector\n",
    "        vector = row.vector\n",
    "        # Add object (including vector) to batch queue\n",
    "        c = batch.add_object(\n",
    "            properties=recommendation_objs,\n",
    "            uuid=generate_uuid5(row.index),\n",
    "            vector=[0.12345] * 1536 # Add the custom vector\n",
    "            # references=reference_obj  # You can add references here\n",
    "        )\n",
    "        print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_objs = list()\n",
    "\n",
    "for i, row in df_product.iterrows():\n",
    "    vector = row['vector'].tolist()\n",
    "    print(vector)\n",
    "    recommendation_objs.append(wvc.data.DataObject(\n",
    "        properties={\n",
    "            \"product_id\": row[\"product_id\"],\n",
    "            \"category_code\": row[\"category_code\"],\n",
    "        },\n",
    "        vector= vector\n",
    "    ))\n",
    "recommencations = client.collections.get(\"RecommenderDB\")\n",
    "recommencations.data.insert_many(recommendation_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing query\n",
    "# Read the last 10 rows of the dataset, load only first 5000 rows\n",
    "last_10_rows = pd.read_csv(dataset, usecols=columns, dtype=dtype_mapping, nrows=5000).tail(10)\n",
    "print(last_10_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_10_rows['merged'] = last_10_rows['event_type'].astype(str) + last_10_rows['product_id'].astype(str)\n",
    "\n",
    "last_10_rows.dropna()\n",
    "last_10_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize a random row\n",
    "def vectorize_random_row(df, model, vocab_map):\n",
    "    while True:\n",
    "        random_row = df.sample(n=1).iloc[0]\n",
    "        if pd.notna(random_row['category_code']) and pd.notna(random_row['product_id']):\n",
    "            item_id = random_row['merged']\n",
    "            vector = vectorize_item(item_id, model, vocab_map)\n",
    "            if vector is not None:\n",
    "                return vector, random_row\n",
    "        # If the selected row has NaN values, continue to select another row\n",
    "\n",
    "# Vectorize a random row from last_10_rows\n",
    "q_vector, random_row = vectorize_random_row(last_10_rows, embedding, vocab_mapping)\n",
    "print(f\"Random Row: {random_row}\")\n",
    "print(f\"Vector: {q_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)  # Sleep so we don't query before async indexing finishes\n",
    "\n",
    "product_recommendation = recommencations.query.near_vector(\n",
    "    near_vector=q_vector,\n",
    "    limit=5,\n",
    "    return_properties=[\"product_id\", \"category_code\"]\n",
    ")\n",
    "\n",
    "print(product_recommendation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Objekte aus einer bestimmten Klasse abrufen\n",
    "result = client.collections.get(\"RecommenderDB\")\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in result.iterator(include_vector=True):\n",
    "    #print(item)\n",
    "    print(item.properties)\n",
    "    print(item.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the response\n",
    "for o in product_recommendation.objects:\n",
    "    print(o.properties[\"product_id\"], o.properties[\"category_code\"])\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
