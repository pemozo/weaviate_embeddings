{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from skipgram import SkipGram\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"yoochoose-clicks.dat\"\n",
    "pkl_file_name= \"yoochoose_trigrams.pkl\"\n",
    "checkpoint_path = \"finished_embedding_YooChooseEmbedding.pt\"\n",
    "\n",
    "columns = [\"session_id\", \"ts\", \"item_id\", \"category_id\"]\n",
    "\n",
    "dtype_mapping = {\n",
    "    \"session_id\": \"UInt32\",\n",
    "    \"ts\": \"str\",\n",
    "    \"item_id\": \"UInt32\",\n",
    "    \"category_id\": \"category\"\n",
    "}\n",
    "\n",
    "context_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the file path from the environment variable\n",
    "file_path = os.getenv(\"PATH_TO_ORIGINAL_DATA\")\n",
    "model_path = os.getenv(\"PATH_TO_MODELS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding-Dimension: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammed Zoghian\\AppData\\Local\\Temp\\ipykernel_28992\\594783483.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path + checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path + checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Check embedding dim\n",
    "embedding_weights = checkpoint[\"model\"][\"embedding.weight\"]\n",
    "embedding_dim = embedding_weights.shape[1]\n",
    "\n",
    "print(f\"Embedding-Dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id                        ts    item_id category_id\n",
      "0           1  2014-04-07T10:51:09.277Z  214536502           0\n",
      "1           1  2014-04-07T10:54:09.868Z  214536500           0\n",
      "2           1  2014-04-07T10:54:46.998Z  214536506           0\n",
      "3           1  2014-04-07T10:57:00.306Z  214577561           0\n",
      "4           2  2014-04-07T13:56:37.614Z  214662742           0\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# Data Source: https://www.kaggle.com/datasets/chadgostopp/recsys-challenge-2015\n",
    "data = pd.read_csv(file_path + file_name, names=columns, dtype=dtype_mapping)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to timestamp (in seconds)\n",
    "data.ts = data.ts.apply(lambda x: int(datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp()))\n",
    "data.sort_values(by=\"ts\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vocabulary mapping from pickle file\n",
    "with open(model_path + pkl_file_name, \"rb\") as f:\n",
    "    pkl_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ngrams', 'actions_map'])\n"
     ]
    }
   ],
   "source": [
    "print(pkl_model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the action mapping\n",
    "if \"actions_map\" in pkl_model:\n",
    "    action_mapping = pkl_model[\"actions_map\"]\n",
    "    #print(\"Action Mapping:\", action_mapping)\n",
    "else:\n",
    "    print(\"Action Mapping not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohammed Zoghian\\Documents\\weaviate_embeddings\\skipgram.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding = SkipGram.create_from_checkpoint(model_path + checkpoint_path, action_mapping, embedding_dim, context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Mapping of the item_ids from the Yoochoose data with the action_mapping\n",
    "data[\"item_id_mapped\"] = data[\"item_id\"].apply(lambda x: action_mapping.get(np.int32(x), len(action_mapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.4318674   4.4825516  -2.544856   ...  0.7612928  -0.9312703\n",
      "   0.6341148 ]\n",
      " [-0.9762234   5.6311107  -2.3641407  ...  0.6059743  -0.9499383\n",
      "  -1.1148039 ]\n",
      " [-1.3192425   4.2692685  -3.398055   ...  0.59222704  1.0682908\n",
      "  -0.70420265]\n",
      " ...\n",
      " [-3.8075075   3.0427346  -1.5741898  ...  2.2775836   0.70090294\n",
      "  -1.9142159 ]\n",
      " [-3.8075075   3.0427346  -1.5741898  ...  2.2775836   0.70090294\n",
      "  -1.9142159 ]\n",
      " [-4.7697096  -4.071556    0.22586069 ...  1.536745   -0.8430815\n",
      "   2.5262337 ]]\n"
     ]
    }
   ],
   "source": [
    "# Function to vectorize items\n",
    "def vectorize_items(item_ids, model):\n",
    "    item_ids_tensor = torch.tensor(item_ids, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.embed(item_ids_tensor)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Calculate the vectors for the first 10 items\n",
    "item_ids = data[\"item_id_mapped\"].tolist()\n",
    "item_vectors = vectorize_items(item_ids, embedding)\n",
    "\n",
    "print(item_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 232371 not found in reverse_action_mapping\n",
      "Key 178656 not found in reverse_action_mapping\n",
      "Key 3732864 not found in reverse_action_mapping\n",
      "Ähnliche Produkte für Item 43438: [np.int32(214840567), np.int32(214827105)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "example_item_id = data[\"item_id_mapped\"].iloc[11]  # Beispiel-Item (numerische ID)\n",
    "example_vector = item_vectors[example_item_id]  # Vektor des Items\n",
    "\n",
    "# Ähnlichkeit berechnen\n",
    "similarities = cosine_similarity([example_vector], item_vectors)\n",
    "\n",
    "# IDs der ähnlichsten Produkte (sortiert nach Ähnlichkeit)\n",
    "similar_indices = np.argsort(similarities[0])[::-1][:5]  # Top 5 ähnliche Produkte\n",
    "\n",
    "# Rückführung der numerischen IDs in die ursprünglichen item_id\n",
    "reverse_action_mapping = {v: k for k, v in action_mapping.items()}  # Mapping umkehren\n",
    "# Check if the key exists in the dictionary before accessing it\n",
    "similar_items = []\n",
    "for idx in similar_indices:\n",
    "    if idx in reverse_action_mapping:\n",
    "        similar_items.append(reverse_action_mapping[idx])\n",
    "    else:\n",
    "        print(f\"Key {idx} not found in reverse_action_mapping\")\n",
    "\n",
    "print(f\"Ähnliche Produkte für Item {example_item_id}: {similar_items}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
